# -*- coding: utf-8 -*-
"""CLI entry point for zero-shot evaluation.

Usage:
    python -m cookbooks.zero_shot_evaluation --config config.yaml
    python -m cookbooks.zero_shot_evaluation --config config.yaml --save
    python -m cookbooks.zero_shot_evaluation --config config.yaml --queries_file queries.json --save
"""

import asyncio
import json
from pathlib import Path
from typing import List, Optional

import fire
from loguru import logger

from cookbooks.zero_shot_evaluation.core.config import load_config
from cookbooks.zero_shot_evaluation.core.evaluator import ZeroShotEvaluator
from cookbooks.zero_shot_evaluation.core.schema import GeneratedQuery


def _load_queries_from_file(queries_file: str) -> List[GeneratedQuery]:
    """Load pre-generated queries from JSON file."""
    with open(queries_file, "r", encoding="utf-8") as f:
        data = json.load(f)
    queries = [GeneratedQuery(**item) for item in data]
    logger.info(f"Loaded {len(queries)} queries from {queries_file}")
    return queries


async def _run_evaluation(
    config_path: str,
    output_dir: Optional[str] = None,
    queries_file: Optional[str] = None,
    save: bool = False,
    resume: bool = True,
) -> None:
    """Run evaluation pipeline.

    Args:
        config_path: Path to configuration file
        output_dir: Output directory (overrides config)
        queries_file: Path to pre-generated queries JSON file (skip generation)
        save: Whether to save results to file
        resume: Whether to resume from checkpoint
    """
    config = load_config(config_path)

    if output_dir:
        config.output.output_dir = output_dir

    # Load pre-generated queries if provided
    queries = None
    if queries_file:
        queries = _load_queries_from_file(queries_file)

    evaluator = ZeroShotEvaluator(config=config, resume=resume)
    result = await evaluator.evaluate(queries=queries)

    if save:
        evaluator.save_results(result, output_dir)


def main(
    config: str,
    output_dir: Optional[str] = None,
    queries_file: Optional[str] = None,
    save: bool = False,
    fresh: bool = False,
) -> None:
    """Zero-shot evaluation CLI with checkpoint support.

    Args:
        config: Path to YAML configuration file
        output_dir: Output directory for results
        queries_file: Path to pre-generated queries JSON (skip query generation)
        save: Whether to save results to file
        fresh: Start fresh, ignore any existing checkpoint

    Examples:
        # Normal run (auto-resumes from checkpoint)
        python -m cookbooks.zero_shot_evaluation --config config.yaml --save
        
        # Use pre-generated queries
        python -m cookbooks.zero_shot_evaluation --config config.yaml --queries_file queries.json --save
        
        # Start fresh, ignore checkpoint
        python -m cookbooks.zero_shot_evaluation --config config.yaml --fresh --save
    """
    config_path = Path(config)
    if not config_path.exists():
        logger.error(f"Config file not found: {config}")
        return

    if queries_file:
        queries_path = Path(queries_file)
        if not queries_path.exists():
            logger.error(f"Queries file not found: {queries_file}")
            return

    logger.info(f"Starting zero-shot evaluation with config: {config}")
    if queries_file:
        logger.info(f"Using pre-generated queries from: {queries_file}")
    if fresh:
        logger.info("Starting fresh (ignoring checkpoint)")
    else:
        logger.info("Resume mode enabled (will continue from checkpoint if exists)")
    
    asyncio.run(_run_evaluation(str(config_path), output_dir, queries_file, save, resume=not fresh))


if __name__ == "__main__":
    fire.Fire(main)

